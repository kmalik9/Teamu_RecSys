{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d4728bb",
   "metadata": {},
   "source": [
    "### DLRM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b3174b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fa35de5",
   "metadata": {},
   "source": [
    "### Load embeddings into datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3227bee1-b393-4ecc-932d-107d9de70359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from google.cloud import storage\n",
    "\n",
    "# GCS paths\n",
    "USER_EMBEDDINGS_PATH = 'gs://vector_bucket/user_embeddings.npy'\n",
    "POST_EMBEDDINGS_PATH = 'gs://vector_bucket/post_embeddings.npy'\n",
    "USER_TFRECORD_PATH = 'gs://user_bucket/*.tfrecord'\n",
    "POST_TFRECORD_PATH = 'gs://post_bucket/*.tfrecord'\n",
    "\n",
    "# Load embeddings from GCS\n",
    "def load_embeddings(gcs_path):\n",
    "    client = storage.Client()\n",
    "    bucket_name, object_name = gcs_path.replace('gs://', '').split('/', 1)\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(object_name)\n",
    "    embedding_bytes = blob.download_as_string()\n",
    "    embeddings_tensor = tf.io.parse_tensor(embedding_bytes, out_type=tf.float32)\n",
    "    return embeddings_tensor\n",
    "\n",
    "user_embeddings = load_embeddings(USER_EMBEDDINGS_PATH)\n",
    "post_embeddings = load_embeddings(POST_EMBEDDINGS_PATH)\n",
    "\n",
    "# Load additional sparse features\n",
    "def load_tfrecord_data(file_pattern, feature_description):\n",
    "    raw_dataset = tf.data.TFRecordDataset(tf.io.gfile.glob(file_pattern))\n",
    "    return raw_dataset.map(lambda x: tf.io.parse_single_example(x, feature_description))\n",
    "\n",
    "user_feature_description = {\n",
    "    'viewed_posts': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'upvoted_posts': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'commented_posts': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'login_frequency': tf.io.FixedLenFeature([], tf.float32)\n",
    "}\n",
    "\n",
    "post_feature_description = {\n",
    "    'post_length': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'vote_count': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'upvote_count': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'view_count': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'comment_count': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'avg_time_viewed': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'ctr': tf.io.FixedLenFeature([], tf.float32)\n",
    "}\n",
    "\n",
    "user_dataset = load_tfrecord_data(USER_TFRECORD_PATH, user_feature_description)\n",
    "post_dataset = load_tfrecord_data(POST_TFRECORD_PATH, post_feature_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce01f86c",
   "metadata": {},
   "source": [
    "### Define and instantiate DLRM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d3b74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DLRM model class\n",
    "class DLRMModel(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, sparse_feature_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Dense layers for sparse features\n",
    "        self.user_sparse_dense = tf.keras.layers.Dense(sparse_feature_dim, activation='relu')\n",
    "        self.post_sparse_dense = tf.keras.layers.Dense(sparse_feature_dim, activation='relu')\n",
    "        \n",
    "        # Final interaction layers\n",
    "        self.interaction_layer = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.output_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, user_emb, post_emb, user_sparse, post_sparse):\n",
    "        \n",
    "        # Process sparse features\n",
    "        user_sparse_vector = self.user_sparse_dense(user_sparse)\n",
    "        post_sparse_vector = self.post_sparse_dense(post_sparse)\n",
    "        \n",
    "        # Concatenate all features\n",
    "        interaction = tf.concat([user_emb, post_emb, user_sparse_vector, post_sparse_vector], axis=1)\n",
    "        \n",
    "        # Final interaction and prediction\n",
    "        x = self.interaction_layer(interaction)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Model instantiation\n",
    "embedding_dim = 32\n",
    "sparse_feature_dim = 16\n",
    "dlrm_model = DLRMModel(embedding_dim, sparse_feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabe102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 5\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    \n",
    "    for user, post in zip(user_dataset.batch(BATCH_SIZE), post_dataset.batch(BATCH_SIZE)):\n",
    "        with tf.GradientTape() as tape:\n",
    "            user_emb = user_embeddings\n",
    "            post_emb = post_embeddings\n",
    "\n",
    "            user_sparse = tf.stack([user['viewed_posts'], user['upvoted_posts'], user['commented_posts'], user['login_frequency']], axis=1)\n",
    "            post_sparse = tf.stack([post['post_length'], post['vote_count'], post['upvote_count'], post['view_count'], post['comment_count'], post['avg_time_viewed'], post['ctr']], axis=1)\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = dlrm_model(user_emb, post_emb, user_sparse, post_sparse)\n",
    "\n",
    "            # Use binary cross-entropy as the loss\n",
    "            labels = tf.ones_like(predictions)  # Replace with actual labels if available\n",
    "            loss = tf.keras.losses.binary_crossentropy(labels, predictions)\n",
    "\n",
    "        # Backward pass\n",
    "        gradients = tape.gradient(loss, dlrm_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, dlrm_model.trainable_variables))\n",
    "\n",
    "    print(f\"Loss: {tf.reduce_mean(loss).numpy()}\")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Save the trained model for inference or further usage\n",
    "dlrm_model.save(\"gs://model_bucket/models/dlrm_model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
